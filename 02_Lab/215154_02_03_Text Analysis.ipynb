{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Practice lab\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# **Scenario: Text Analysis**\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Text analysis?\n",
    "Text analysis, also known as text mining or text analytics, refers to the process of extracting meaningful information and insights from textual data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    " \n",
    "After completing this lab, you will be able to use Python commands to perform text analysis. This includes converting the text to lowercase and then finding and counting the frequency of all unique words, as well as a specified word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following data types:\n",
    "* List\n",
    "* Strings\n",
    "* Classes and objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's consider a real-life scenario where you are analyzing customer feedback for a product. You have a large dataset of customer reviews in the form of strings, and you want to extract useful information from them using the three identified tasks:\n",
    "\n",
    "**Task 1. String in lower case:**\n",
    "You want to Pre-process the customer feedback by converting all the text to lowercase. This step helps standardize the text. Lower casing the text allows you to focus on the content rather than the specific letter casing.\n",
    "\n",
    "**Task 2. Frequency of all words in a given string:**\n",
    "After converting the text to lowercase, you want to determine the frequency of each word in the customer feedback. This information will help you identify which words are used more frequently, indicating the key aspects or topics that customers are mentioning in their reviews. By analyzing the word frequencies, you can gain insights into the most common issues raised by customers.\n",
    "\n",
    "**Task 3. Frequency of a specific word:**\n",
    "In addition to analyzing the overall word frequencies, you want to specifically track the frequency of a particular word that is relevant to your analysis. For example, you might be interested in monitoring how often the word \"reliable\" appears in the customer reviews to gauge customer sentiment about the product's reliability. By focusing on the frequency of a specific word, you can gain a deeper understanding of customer opinions or preferences related to that particular aspect.\n",
    "\n",
    "By performing these tasks on the customer feedback dataset, you can gain valuable insights into customer sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# Part-A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "**Note:- In Part-A, you won't be getting any output as we are just storing the string and creating a class.**\n",
    "    </center>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1 Define a string. \n",
    "\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\" <br>\n",
    "**Hint:- Use a variable and store the above string.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Press Shift+Enter to run the code\n",
    "givenstring=\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For achieving the tasks mentioned in the scenario, We need to create a class with 3 different methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2 Define the class and its attributes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a class named TextAnalyzer.\n",
    "2. Define the constructor `__init__` method that takes a text argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (849867507.py, line 7)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef __init__(self, text):\u001b[39m\n                             ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Please do not run this code cell as it is incomplete and will produce an error.\n",
    "\n",
    "# Let's create a class called TextAnalyzer to analyze text.\n",
    "class TextAnalyzer(object):\n",
    "    # The __init__ method initializes the class with a 'text' parameter.\n",
    "    # We will store the provided 'text' as an instance variable.\n",
    "    def __init__(self, text):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3 Implement a code to Format the text in Lowercase:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inside the constructor,we will convert the text argument to lowercase using the `lower()` method.\n",
    "2. Then, will Remove punctuation marks (periods, exclamation marks, commas, and question marks) from the text using the `replace()` method.\n",
    "3. At last, we will Assign the formatted text to a new attribute called fmtText.\n",
    "\n",
    "**Here we will be Updating the above `TextAnalyzer` class with points mentioned above.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press Shift+Enter to run the code.\n",
    "class TextAnalzer(object):\n",
    "    \n",
    "    def __init__ (self, text):\n",
    "        # remove punctuation\n",
    "        \n",
    "        # make text lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "class TextAnalzer(object):\n",
    "    \n",
    "    def __init__ (self, text):\n",
    "        # remove punctuation\n",
    "        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n",
    "        \n",
    "        # make text lowercase\n",
    "        formattedText = formattedText.lower()\n",
    "        \n",
    "        self.fmtText = formattedText\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4 Implement a code to count the Frequency of all unique words:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this step, we will Implement the `freqAll()` method with the below parameters:\n",
    "     1. Split the fmtText attribute into individual words using the `split()` method.\n",
    "     2. Create an empty dictionary to store the word frequency.\n",
    "     3. Iterate over the list of words and update the frequency dictionary accordingly.\n",
    "     4. Use `count` method for counting the occurence\n",
    "     5. Return the frequency dictionary.\n",
    "     \n",
    "**Update the above `TextAnalyzer` class with points mentioned above.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Press shift+Enter to run the code\n",
    "class TextAnalyzer(object):\n",
    "    \n",
    "    def __init__ (self, text):\n",
    "        # remove punctuation\n",
    "        \n",
    "        # make text lowercase\n",
    "        \n",
    "    def freqAll(self):        \n",
    "        # split text into words\n",
    "        \n",
    "        # Create dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "class TextAnalyzer(object):\n",
    "    \n",
    "    def __init__ (self, text):\n",
    "        # remove punctuation\n",
    "        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n",
    "        \n",
    "        # make text lowercase\n",
    "        formattedText = formattedText.lower()\n",
    "        \n",
    "        self.fmtText = formattedText\n",
    "        \n",
    "    def freqAll(self):        \n",
    "        # split text into words\n",
    "        wordList = self.fmtText.split(' ')\n",
    "        \n",
    "        # Create dictionary\n",
    "        freqMap = {}\n",
    "        for word in set(wordList): # use set to remove duplicates in list\n",
    "            freqMap[word] = wordList.count(word)\n",
    "        \n",
    "        return freqMap\n",
    "```\n",
    "    \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5 Implement a code to count the Frequency of a specific word:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In step-5, we have to Implement the `freqOf(word)` method that takes a word argument:\n",
    "   1. Create method and pass the word that need to be found\n",
    "   2. Get the `freqAll` method for look for count and check if that word is in the list.\n",
    "   3. Return the count. If the word is not found, the count returned is 0.\n",
    "   \n",
    "**Update the above `TextAnalyzer` class with points mentioned above.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalyzer(object):\n",
    "    \n",
    "    def __init__ (self, text):\n",
    "        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n",
    "    \n",
    "        formattedText = formattedText.lower()\n",
    "        \n",
    "        self.fmtText = formattedText\n",
    "        \n",
    "    def freqAll(self):        \n",
    "        # split text into words\n",
    "        wordList = self.fmtText.split(' ')\n",
    "        \n",
    "        # Create dictionary\n",
    "        freqMap = {}\n",
    "        for word in set(wordList): # use set to remove duplicates in list\n",
    "            freqMap[word] = wordList.count(word)\n",
    "        \n",
    "        return freqMap\n",
    "    \n",
    "    def freqOf(self,word):\n",
    "        # get frequency map\n",
    "        freqDict = self.freqAll()\n",
    "        \n",
    "        if word in freqDict:\n",
    "            return freqDict[word]\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "class TextAnalyzer(object):\n",
    "    \n",
    "    def __init__ (self, text):\n",
    "        # remove punctuation\n",
    "        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n",
    "        \n",
    "        # make text lowercase\n",
    "        formattedText = formattedText.lower()\n",
    "        \n",
    "        self.fmtText = formattedText\n",
    "        \n",
    "    def freqAll(self):        \n",
    "        # split text into words\n",
    "        wordList = self.fmtText.split(' ')\n",
    "        \n",
    "        # Create dictionary\n",
    "        freqMap = {}\n",
    "        for word in set(wordList): # use set to remove duplicates in list\n",
    "            freqMap[word] = wordList.count(word)\n",
    "        \n",
    "        return freqMap\n",
    "    \n",
    "    def freqOf(self,word):\n",
    "        # get frequency map\n",
    "        freqDict = self.freqAll()\n",
    "        \n",
    "        if word in freqDict:\n",
    "            return freqDict[word]\n",
    "        else:\n",
    "            return 0\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, We have successfully created a class with 3 methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# Part-B \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "**In Part B, we will be calling the functions created in Part A, allowing the functions to execute and generate output.**\n",
    "    </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1 Create an instance of TextAnalyzer Class.\n",
    "* Instantiate the TextAnalyzer class by passing the given string as an argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "textAnalyzer=TextAnalyzer(\"Lorem ipsum dolor sit amet. Et nostrum dolores est ipsam temporibus et corrupti dolor. In nostrum omnis eos tempore fuga sit nostrum voluptas et odit eius. Ad dolorem magnam in itaque laborum ut culpa dignissimos non iusto repudiandae! Quo fugit eaque est velit dolor aut galisum nesciunt.Nam cumque velit est labore quisquam est accusantium rerum quo minus alias qui nisi ipsam et quia excepturi et sunt molestiae. Id voluptatem voluptates et impedit harum 33 quam nostrum et nostrum alias id vitae tempora et eaque iste. Qui velit cupiditate qui molestiae sint qui aperiam voluptatem ex dicta unde. Non quis nisi sed minima fuga qui doloremque maxime? Ut consectetur velit ea delectus quas ut nulla porro rem magnam quaerat et perferendis rerum non nisi sunt sit temporibus placeat. Aut sunt vero ad eligendi earum aut amet quis sed itaque magni eum aspernatur facere? Ab minima saepe ex quaerat rerum qui vitae officia et accusamus iure sit voluptatem expedita!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "analyzed = TextAnalyzer(givenstring)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2  Call the function that converts the data into lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formated TText :  lorem ipsum dolor sit amet et nostrum dolores est ipsam temporibus et corrupti dolor in nostrum omnis eos tempore fuga sit nostrum voluptas et odit eius ad dolorem magnam in itaque laborum ut culpa dignissimos non iusto repudiandae quo fugit eaque est velit dolor aut galisum nesciuntnam cumque velit est labore quisquam est accusantium rerum quo minus alias qui nisi ipsam et quia excepturi et sunt molestiae id voluptatem voluptates et impedit harum 33 quam nostrum et nostrum alias id vitae tempora et eaque iste qui velit cupiditate qui molestiae sint qui aperiam voluptatem ex dicta unde non quis nisi sed minima fuga qui doloremque maxime ut consectetur velit ea delectus quas ut nulla porro rem magnam quaerat et perferendis rerum non nisi sunt sit temporibus placeat aut sunt vero ad eligendi earum aut amet quis sed itaque magni eum aspernatur facere ab minima saepe ex quaerat rerum qui vitae officia et accusamus iure sit voluptatem expedita\n"
     ]
    }
   ],
   "source": [
    "print(\"Formated TText : \",textAnalyzer.fmtText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "print(\"Formatted Text:\", analyzed.fmtText)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully converted string into lowercase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3 Call the function that counts the frequency of all unique words from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quas': 1,\n",
       " 'aspernatur': 1,\n",
       " 'impedit': 1,\n",
       " 'doloremque': 1,\n",
       " 'aut': 3,\n",
       " 'voluptas': 1,\n",
       " 'labore': 1,\n",
       " 'minima': 2,\n",
       " 'dicta': 1,\n",
       " 'est': 4,\n",
       " 'amet': 2,\n",
       " 'ipsam': 2,\n",
       " 'dignissimos': 1,\n",
       " 'molestiae': 2,\n",
       " 'accusantium': 1,\n",
       " 'velit': 4,\n",
       " 'et': 10,\n",
       " 'itaque': 2,\n",
       " 'facere': 1,\n",
       " 'eum': 1,\n",
       " 'quam': 1,\n",
       " 'eaque': 2,\n",
       " 'saepe': 1,\n",
       " 'aperiam': 1,\n",
       " 'rem': 1,\n",
       " 'temporibus': 2,\n",
       " 'porro': 1,\n",
       " 'eius': 1,\n",
       " 'id': 2,\n",
       " 'iure': 1,\n",
       " 'quo': 2,\n",
       " 'ex': 2,\n",
       " 'quisquam': 1,\n",
       " 'harum': 1,\n",
       " 'quia': 1,\n",
       " 'iste': 1,\n",
       " 'officia': 1,\n",
       " 'maxime': 1,\n",
       " 'unde': 1,\n",
       " 'ea': 1,\n",
       " 'qui': 6,\n",
       " 'cupiditate': 1,\n",
       " 'repudiandae': 1,\n",
       " 'corrupti': 1,\n",
       " 'fuga': 2,\n",
       " 'odit': 1,\n",
       " 'tempore': 1,\n",
       " 'consectetur': 1,\n",
       " 'eos': 1,\n",
       " 'quaerat': 2,\n",
       " 'rerum': 3,\n",
       " 'alias': 2,\n",
       " 'ab': 1,\n",
       " 'nostrum': 5,\n",
       " 'earum': 1,\n",
       " 'ut': 3,\n",
       " 'dolor': 3,\n",
       " 'vitae': 2,\n",
       " '33': 1,\n",
       " 'voluptates': 1,\n",
       " 'dolores': 1,\n",
       " 'ipsum': 1,\n",
       " 'minus': 1,\n",
       " 'expedita': 1,\n",
       " 'magnam': 2,\n",
       " 'perferendis': 1,\n",
       " 'omnis': 1,\n",
       " 'sit': 4,\n",
       " 'voluptatem': 3,\n",
       " 'sunt': 3,\n",
       " 'laborum': 1,\n",
       " 'in': 2,\n",
       " 'dolorem': 1,\n",
       " 'culpa': 1,\n",
       " 'sint': 1,\n",
       " 'vero': 1,\n",
       " 'eligendi': 1,\n",
       " 'excepturi': 1,\n",
       " 'magni': 1,\n",
       " 'tempora': 1,\n",
       " 'fugit': 1,\n",
       " 'delectus': 1,\n",
       " 'cumque': 1,\n",
       " 'quis': 2,\n",
       " 'placeat': 1,\n",
       " 'galisum': 1,\n",
       " 'nesciuntnam': 1,\n",
       " 'lorem': 1,\n",
       " 'nulla': 1,\n",
       " 'ad': 2,\n",
       " 'sed': 2,\n",
       " 'iusto': 1,\n",
       " 'nisi': 3,\n",
       " 'accusamus': 1,\n",
       " 'non': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textAnalyzer.freqAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "freqMap = analyzed.freqAll()\n",
    "print(freqMap)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully calculated the frequency of all unique words in the string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4 Call the function that counts the frequency of specific word.\n",
    "Here, we will call the function that counts the frequency of the word \"lorem\"\n",
    "<br>\n",
    "\n",
    "Print the output.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textAnalyzer.freqOf(\"aut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "word = \"lorem\"\n",
    "frequency = analyzed.freqOf(word)\n",
    "print(\"The word\",word,\"appears\",frequency,\"times.\")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully calculated the frequency of all specified words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Akansha yadav**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "| 2024-01-18 | 2.3 | Ghulam Ali | Updated some content and instructions|\n",
    "|2023-11-05|0.4|Abhishek Gagneja| Updated lab instructions|\n",
    "|2023-05-17|0.3|Akansha yadav| Created lab under maintenance|\n",
    "|2020-07-17|0.1|Sam     |Create Lab Template|\n",
    "|2022-11-19|0.2|Shengkai|Update Lab Template|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
